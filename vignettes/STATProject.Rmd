---
title: "STATProject"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{STATProject}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
params:
  data_file: project.csv
bibliography: Project.bib
nocite: '@*'
---

```{r setup, include=FALSE}
# Examiners: For High Distinction, I have interpreted that you would alter the output in YAML to html or use a different data file with same structure. If you were to change the data file name, please insert that name in the params-data_file in the YAML!

knitr::opts_chunk$set(echo = FALSE)

packages <- c("tidyverse", "knitr", "rmarkdown","roxygen2","testthat","usethis","devtools","ggplot2","ggrepel","stats","kableExtra","bookdown","shiny","patchwork","dplyr")
lapply(packages, library, character.only=TRUE)
install_github("david-yunbae/Project2")
devtools::load_all()
library(STATProject)
```

\tableofcontents
\pagebreak

# Abstract
This is the final demonstration of my skills and understanding in the statistical testing and writing in R. The three statistical tests that would be discussed are linear regression, t test and the $\chi^2$ test. The package is separate to the codes in this report, but I have copied and pasted the code chunks from the package. In this way, the two parts of the project are quite closely linked.

Please enjoy!

\pagebreak

# Linear regression test
The first research question is whether there is a linear relationship between heights and weights of the sample population. The $\beta$ is being tested, so the sampling distribution is: $\hat{\beta}\sim N(\beta,\frac{\sigma^2}{S_{xx}})$.

\
$H_{0}:\beta=0$ against $H_{1}:\beta \neq 0$
\

We assume the linear regression model is appropriate: $Y_{i}=\alpha+\beta X_{i}+\epsilon_{i}$, where $\epsilon_{i}$ are independent and identically distributed $N(0,\sigma^2)$.

Test statistic: $\tau=\frac{\hat{\beta}}{s_{Y \mid X}/\sqrt{S_{xx}}} \sim t_{n-2}$ under $H_{0}$.

$\tau_{obs}=$ `r summary(lm(formula = height ~ weight, data = read_csv("project.csv")))$coefficients[[5]]`

\
Making a proper linear regression decision requires the linearity between the two variables, constant variance and normality of the residuals. In fact, these are all assumed to hold already. The following graphs must show the linearity, evenly dispersed residuals and a bell shaped histogram of the residuals vs fitted values:

```{r assumption, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
  #Prepare assumption for lm
  D <- lm(height ~ weight,dat)
  a <- ggplot2::ggplot(dat,aes(x=height,y=weight))+ geom_point() + stat_smooth(method="lm", col="red") +ggtitle("I) Y vs X")

  b <- ggplot2::ggplot(dat)+geom_point(mapping=aes(x=D$fitted.values ,y=D$residuals)) + geom_hline(yintercept=0,lwd=2)+ggtitle("II) Residual plot")+ylab("Residuals")+xlab("Fitted values")

  c <- ggplot2::ggplot(dat)+geom_histogram(mapping=aes(x=D$residuals),bins=40) +ggtitle("III) Distribution is normal")+xlab("Residuals")

  #Prepare assumption for ttest
  d <- ggplot2::ggplot(dat, aes(sample=height, group=gender, colour=gender))+geom_qq()+geom_qq_line()+xlab("theoretical")+ylab("sample")

  e <- dat %>% dplyr::group_by(gender) %>% dplyr::summarise(n=n(),mu=mean(height),sd=sd(height))

  #Preapre assumption for chitest
  datm <- dat %>% dplyr::filter(gender=="Male") %>% dplyr::select(phys)
  datf <- dat %>% dplyr::filter(gender=="Female") %>% dplyr::select(phys)

  datmn <- datm %>% dplyr::filter(phys=="None") %>% dplyr::count()
  datmm <- datm %>% dplyr::filter(phys=="Moderate") %>% dplyr::count()
  datmi <- datm %>% dplyr::filter(phys=="Intense") %>% dplyr::count()

  datfn <- datf %>% dplyr::filter(phys=="None") %>% dplyr::count()
  datfm <- datf %>% dplyr::filter(phys=="Moderate") %>% dplyr::count()
  datfi <- datf %>% dplyr::filter(phys=="Intense") %>% dplyr::count()

  table <- dplyr::tibble(Male=c(datmn[[1]],datmm[[1]],datmi[[1]]),Female=c(datfn[[1]],datfm[[1]],datfi[[1]]))

  print((a+b)/c)

```

Once it is clear that these assumptions are met, the P value can then be computed directly using the r function lm().

The computed P value is `r broom::glance(lm(height~weight,dat))$p.value`. With this P value, it is possible to make the conclusion about the test:

```{r pvaluelm, echo=FALSE, message=TRUE, warning=FALSE, fig.align="center" }

if (broom::glance(lm(height~weight,dat))$p.value < 0.05) {
  cat("REJECT H0: ", broom::glance(lm(height~weight,dat))$p.value, " < 0.05\n \n")
  cat(str_wrap("There is a relationship between height and weight: As the P-value is very small, we have very strong evidence to reject H0. I.E. very strong evidence that the slope parameter is significant and there is a relationship between the height and weight of the sample population."), "\n")
} else {
  cat("DO NOT REJECT H0: ", broom::glance(lm(height~weight,dat))$p.value, " > 0.05\n \n")
  cat(str_wrap("There isn't any relationship between height and weight: As the P-value is large, we have no evidence to reject H0. I.E. no evidence that the slope parameter is significant and there isn't any relationship between the height and weight of the sample population."), "\n")
}

datm <- dat %>% filter(gender=="Male") %>% select(height)
datf <- dat %>% filter(gender=="Female") %>% select(height)

test <- t.test(datm,datf,var.equal=TRUE)

```

\pagebreak

# T test
The next test is about the mean heights of male and female. It is to test if they are same or not. The t test is based on equal variances assumption. Assuming the null hypothesis $H_{0}:\mu_{1} = \mu_{2}$, the resulting sampling distribution is $\frac{\overline{X_{1}}-\overline{X_{2}}}{\sigma\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}\sim N(0,1)$.

\
$H_{0}:\mu_{1}=\mu_{2}$ against $H_{1}:\mu_{1}\neq\mu_{2}$
\

Test statistic: $\tau=\frac{\overline{X_{1}}-\overline{X_{2}}}{s_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}\sim t_{n_{1}+n_{2}-2}$, if $H_{0}$ is true.

$\tau_{obs}=$ `r test[[1]][[1]]`.

\
2 conditions must be met to carry out this test. The normal distribution and equal variance must hold. Firstly, the QQ plot can be examined to confirm the normality assumption:

```{r qqplot, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
d <- ggplot2::ggplot(dat, aes(sample=height, group=gender, colour=gender))+geom_qq()+geom_qq_line()+xlab("theoretical")+ylab("sample")
e <- dat %>% group_by(gender) %>% summarise(n=n(),mu=mean(height),sd=sd(height))

print(d)

datm <- dat %>% filter(gender=="Male") %>% select(height)
datf <- dat %>% filter(gender=="Female") %>% select(height)

test <- t.test(datm,datf,var.equal=TRUE)
```

Since the equal variance is assumed, the larger standard deviation divided by the smaller must not exceed 2. The larger is `r max(e$sd)` and the smaller is `r min(e$sd)`. The division gives `r max(e$sd)/min(e$sd)`.

Once all assumptions are confirmed to hold, the t.test() function directly outputs the P value (`r test[[3]][[1]]`) and the conclusion can be made:

```{r pvaluettest, echo=FALSE, message=TRUE, warning=FALSE, fig.align="center" }

if (test[[3]][[1]] < 0.05) {
  cat("REJECT H0: ", test[[3]][[1]], " < 0.05\n \n")
  cat(str_wrap("The mean height of male and female are NOT the same: As the P-value is very small, we have very strong evidence to reject H0. I.E. very strong evidence that the mean height of male is not the same as the mean height of female."), "\n")
} else {
  cat("DO NOT REJECT H0: ", test[[3]][[1]], " > 0.05\n \n")
  cat(str_wrap("The mean height of male and female are the same: As the P-value is large, we have no evidence to reject H0. I.E. no evidence that the mean height of male is not the same as the mean height of female."), "\n")
}

  #chi test
  datm <- dat %>% filter(gender=="Male") %>% select(phys)
  datf <- dat %>% filter(gender=="Female") %>% select(phys)

  datmn <- datm %>% filter(phys=="None") %>% count()
  datmm <- datm %>% filter(phys=="Moderate") %>% count()
  datmi <- datm %>% filter(phys=="Intense") %>% count()

  datfn <- datf %>% filter(phys=="None") %>% count()
  datfm <- datf %>% filter(phys=="Moderate") %>% count()
  datfi <- datf %>% filter(phys=="Intense") %>% count()

  table <- dplyr::tibble(Male=c(datmn[[1]],datmm[[1]],datmi[[1]]),Female=c(datfn[[1]],datfm[[1]],datfi[[1]]))
  test <- chisq.test(table,correct=FALSE)

```

\pagebreak

# $\chi^2$ test
The last test is to see if male and female have different amount of physical activity. In other words, if gender affects the amount of physical activity. In terms of statistics, this is equivalent to saying there is association between the two variables gender and physical activity. A $\chi^2$ distribution is constructed by squaring a single standard normal distribution: $Q\sim \chi_{i}^2$ where Q is an example of a $\chi^2$ distribution. Then $Q=Z^2$ where $Z\sim N(0,1)$.

\
$H_{0}:$ the two variables are independent against each other. $H_{1}:$ not $H_{0}$.
\

The Pearson's $\chi^2$ test-statistic (without continuity correction) for the test of independence is:
$\tau=\sum^{r}_{i=1}\sum^{c}_{j=1}\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\sim \chi_{(r-1)(c-1)}^2$, under $H_{0}$.

$\tau_{obs}=$ `r test[[1]][[1]]`.
\

Since the test is based on the normal approximation, all entries ($O_{ij}$ and $E_{ij}$) in the table below must be at least 5:

```{r pvaluechitest, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
  
  print(mutate(tibble('Physical activity'=c("None","Moderate","Intense")),table))
  
```

Assuming they are all greater than or equal to 5, the P value can then be generated with the chisq.test() function. The P value is `r test[[3]][[1]]`. Based on this P value, the conclusion to the test can be made:

```{r chitest, echo=FALSE, message=TRUE, warning=FALSE, fig.align="center"}

if (test[[3]][[1]] < 0.05){
  cat("REJECT H0: ", test[[3]][[1]], " < 0.05\n \n")
  cat(str_wrap("Gender affects the amount of physical activity: As the P-value is very small, we have very strong evidence to reject H0. I.E. very strong evidence that the two variables are dependent against each other. Gender affects the physical activity."),"\n")
} else {
  cat("DO NOT REJECT H0: ", test[[3]][[1]], " > 0.05\n \n")
  cat(str_wrap("Gender does NOT affect the amount of physical activity: As the P-value is large, we have no evidence to reject H0. I.E. no evidence that the two variables are dependent against each other. The two variables are independent against each other and there is no association between gender and the amount of physical acitivity."), "\n")
}

```


```{r test, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center"}
  
  #Prepare assumption for lm
  D <- lm(height ~ weight,dat)
  a <- ggplot2::ggplot(dat,aes(x=height,y=weight))+ geom_point() + stat_smooth(method="lm", col="red") +ggtitle("I) Y vs X")
  
  b <- ggplot2::ggplot(dat)+geom_point(mapping=aes(x=D$fitted.values ,y=D$residuals)) + geom_hline(yintercept=0,lwd=2)+ggtitle("II) Residual plot")+ylab("Residuals")+xlab("Fitted values")
  
  c <- ggplot2::ggplot(dat)+geom_histogram(mapping=aes(x=D$residuals),bins=40) +ggtitle("III) Distribution is normal")+xlab("Residuals")
  
  #Prepare assumption for ttest
  d <- ggplot2::ggplot(dat, aes(sample=height, group=gender, colour=gender))+geom_qq()+geom_qq_line()+xlab("theoretical")+ylab("sample")
  
  e <- dat %>% group_by(gender) %>% summarise(n=n(),mu=mean(height),sd=sd(height))
  
  #Preapre assumption for chitest
  datm <- dat %>% filter(gender=="Male") %>% select(phys)
  datf <- dat %>% filter(gender=="Female") %>% select(phys)
  
  datmn <- datm %>% filter(phys=="None") %>% count()
  datmm <- datm %>% filter(phys=="Moderate") %>% count()
  datmi <- datm %>% filter(phys=="Intense") %>% count()
  
  datfn <- datf %>% filter(phys=="None") %>% count()
  datfm <- datf %>% filter(phys=="Moderate") %>% count()
  datfi <- datf %>% filter(phys=="Intense") %>% count()
  
  table <- dplyr::tibble(Male=c(datmn[[1]],datmm[[1]],datmi[[1]]),Female=c(datfn[[1]],datfm[[1]],datfi[[1]]))

```

\pagebreak

# References
